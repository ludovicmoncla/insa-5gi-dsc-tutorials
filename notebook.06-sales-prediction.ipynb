{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.115405,
     "end_time": "2021-01-13T16:26:56.736305",
     "exception": false,
     "start_time": "2021-01-13T16:26:56.620900",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "![INSA](https://gi.insa-lyon.fr/sites/all/themes/insa_satellites/logo.png)\n",
    "\n",
    "# GI-5-DSC - Data Science: Sales prediction and fraud detection\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.107683,
     "end_time": "2021-01-13T16:26:57.185510",
     "exception": false,
     "start_time": "2021-01-13T16:26:57.077827",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In this tutorial, we will perform a comparison study of forecasting methods. More specifically, we will compare the performances of traditional machine learning techniques with neural networks and we will experiment both classification and regression on the same dataset.\n",
    "\n",
    "The dataset used in this tutorial is maintained transparently with the Creative Commons 4.0 license by Fabian Constante, Fernando Silva, and Ant√≥nio Pereira through the Mendeley data repository. It consists of roughly 180k transactions from supply chains used by the company DataCo Global for 3 years (from 2015 to 2018). The dataset can be downloaded from:\n",
    "\n",
    "https://data.mendeley.com/datasets/8gx2fvg2k6/5\n",
    "\n",
    "It contains 3 files:\n",
    "\n",
    "1. DescriptionDataCoSupplyChain.csv: the description of each of the variables of the DataCoSupplyChainDatasetc.csv.\n",
    "2. DataCoSupplyChain.csv: structured data\n",
    "3. tokenized_access_logs.csv: unstructured data\n",
    "\n",
    "\n",
    "We will train deep neural networks and machine learning models for:\n",
    "1. Classification\n",
    " * detection of fraud transactions, \n",
    " * late delivery of orders, \n",
    "2. Regression\n",
    " * sales revenue,\n",
    " * order quantity.\n",
    "\n",
    "\n",
    "The machine learning classifiers used in this project for fraud transactions and late delivery are Logistic Regression, Linear Discriminant Analysis, Gaussian Naive Bayes, Support Vector Machines, k - Nearest Neighbors, Decision Tree classification, and Random Forest classification.\n",
    "These models will be evaluated and compared using accuracy and F1 score. \n",
    "\n",
    "The regression models used to predict sales and quantity of the products required are Lasso, Ridge, Light Gradient boosting, Decision Tree Regression, Random Forest regression, and Linear Regression.\n",
    "These models will be evaluated and compared with mean absolute error (MAE) and root mean square error (RMSE).\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set up the Environment : import libraries & read the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.109368,
     "end_time": "2021-01-13T16:26:57.852058",
     "exception": false,
     "start_time": "2021-01-13T16:26:57.742690",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1.1. Importing all required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 9.912976,
     "end_time": "2021-01-13T16:27:07.875791",
     "exception": false,
     "start_time": "2021-01-13T16:26:57.962815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "import calendar,warnings,itertools,matplotlib,keras,shutil\n",
    "import tensorflow as tf\n",
    "import statsmodels.api as sm\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.model_selection import train_test_split,cross_val_score, cross_val_predict\n",
    "from sklearn import svm,metrics,tree,preprocessing,linear_model\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import Ridge,LinearRegression,LogisticRegression,ElasticNet, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor,RandomForestClassifier, GradientBoostingRegressor,BaggingClassifier,ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score,mean_squared_error,recall_score,confusion_matrix,f1_score,roc_curve, auc\n",
    "from sklearn.datasets import load_iris,make_regression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "from IPython.core import display as ICD\n",
    "\n",
    "## hiding the warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Import data and take a first look at it\n",
    "\n",
    "\n",
    "Use the [read_csv()](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html) method from the Pandas library to load the `DataCoSupplyChain.csv` file into a dataframe. \n",
    "\n",
    "Hint: you need to use the `encoding='unicode_escape'` param for this dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 4.284413,
     "end_time": "2021-01-13T16:27:12.270090",
     "exception": false,
     "start_time": "2021-01-13T16:27:07.985677",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Importing Dataset using pandas\n",
    "## Your code here\n",
    "data = ******\n",
    "\n",
    "data.head() # Checking 5 rows in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.119617,
     "end_time": "2021-01-13T16:27:12.721420",
     "exception": false,
     "start_time": "2021-01-13T16:27:12.601803",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Print the number of row and column of the dataset\n",
    "## Your code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to the 'non-null' column we can notice that some data are missing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.110607,
     "end_time": "2021-01-13T16:27:12.490942",
     "exception": false,
     "start_time": "2021-01-13T16:27:12.380335",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Exploratory data analysis\n",
    "\n",
    "### 2.1. Data cleaning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.110054,
     "end_time": "2021-01-13T16:27:15.216935",
     "exception": false,
     "start_time": "2021-01-13T16:27:15.106881",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "As we saw before, there are some missing values from `Customer Lname`, `Product Description`, `Order Zipcode` and, `Customer Zipcode` which should be removed or replaced before proceeding with the analysis.\n",
    "\n",
    "\n",
    "Then, since there is a chance that different customers might have the same first name or same last name a new column with `Customer Full Name` is created to avoid any ambiguities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.256532,
     "end_time": "2021-01-13T16:27:15.584816",
     "exception": false,
     "start_time": "2021-01-13T16:27:15.328284",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Adding first name and last name together to create new column\n",
    "data['Customer Full Name'] = data['Customer Fname'].astype(str) + data['Customer Lname'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.111895,
     "end_time": "2021-01-13T16:27:15.807395",
     "exception": false,
     "start_time": "2021-01-13T16:27:15.695500",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "To make it easier for analysis some unimportant columns are dropped: `Customer Fname`,`Customer Lname`,`Product Description`,`Customer Email`,`Product Status`,`Customer Password`,`Customer Street`,\n",
    "           `Latitude`,`Longitude`,`Product Image`,`Order Zipcode`,`shipping date (DateOrders)`.\n",
    "\n",
    "Hint: Use the [drop()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html) method from the Pandas library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.295163,
     "end_time": "2021-01-13T16:27:16.213861",
     "exception": false,
     "start_time": "2021-01-13T16:27:15.918698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Drop the columns\n",
    "# Your code here\n",
    "data = *****\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check that the number of column has decreased\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.111105,
     "end_time": "2021-01-13T16:27:16.436649",
     "exception": false,
     "start_time": "2021-01-13T16:27:16.325544",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "There are 3 missing values in `Customer Zipcode` column. \n",
    "Since the missing values are just zip codes which are not very important these are replaced with zero before proceeding with data analysis.\n",
    "\n",
    "Hint: Use the [fillna()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.fillna.html) method from the Pandas library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.121587,
     "end_time": "2021-01-13T16:27:16.668823",
     "exception": false,
     "start_time": "2021-01-13T16:27:16.547236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Filling NaN columns with zero. Tips: use the fillna method from the pandas library\n",
    "# Your code here\n",
    "data['Customer Zipcode'] = *****\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.113109,
     "end_time": "2021-01-13T16:27:16.893467",
     "exception": false,
     "start_time": "2021-01-13T16:27:16.780358",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 3.2. Data Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.110572,
     "end_time": "2021-01-13T16:27:17.115335",
     "exception": false,
     "start_time": "2021-01-13T16:27:17.004763",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "To find important parameters, data correlation is performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 2.787884,
     "end_time": "2021-01-13T16:27:20.013990",
     "exception": false,
     "start_time": "2021-01-13T16:27:17.226106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(24,12))\n",
    "\n",
    "## Plot heatmap for correlation matrix\n",
    "sns.heatmap(data.corr(), annot=True, linewidths=.5, fmt='.1g', cmap= 'coolwarm') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.117616,
     "end_time": "2021-01-13T16:27:20.248256",
     "exception": false,
     "start_time": "2021-01-13T16:27:20.130640",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "For instance, we can observe that `Product Price` has high correlation with `Sales per customer`, `Order Item Product Price`, `Sales`, and `Order Item Total`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.117497,
     "end_time": "2021-01-13T16:27:20.484646",
     "exception": false,
     "start_time": "2021-01-13T16:27:20.367149",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "As the data which is being used for analysis is related to Supply chain, it makes sense to find which region has most sales? \n",
    "It can be found by using groupby method which will segregate similar market regions together and add all sales for that particular region using 'sum' function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.602284,
     "end_time": "2021-01-13T16:27:21.206149",
     "exception": false,
     "start_time": "2021-01-13T16:27:20.603865",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Grouping by market\n",
    "# Your code here\n",
    "market = *****\n",
    "\n",
    "## Grouping by order region\n",
    "# Your code here\n",
    "region = *****\n",
    "\n",
    "plt.figure(figsize=(20, 6))\n",
    "\n",
    "plt.subplot(121)\n",
    "******.sum().sort_values(ascending=False).plot.bar(title=\"Total sales per customer for all markets\")\n",
    "\n",
    "plt.subplot(122)\n",
    "******.sum().sort_values(ascending=False).plot.bar(title=\"Total sales per customer for all regions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.119286,
     "end_time": "2021-01-13T16:27:21.494382",
     "exception": false,
     "start_time": "2021-01-13T16:27:21.375096",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "It could be seen from the graph that European market has the most number of sales whereas Africa has the least. In these markets western europe regions and central america recorded highest sales. \n",
    "\n",
    "Which catergory of products has highest sales? The same method can be followed here to see the product category with highest sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 1.693027,
     "end_time": "2021-01-13T16:27:23.333677",
     "exception": false,
     "start_time": "2021-01-13T16:27:21.640650",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Plot the total sales, average sales and average price per category\n",
    "\n",
    "# Your code here\n",
    "******\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.124445,
     "end_time": "2021-01-13T16:27:23.583715",
     "exception": false,
     "start_time": "2021-01-13T16:27:23.459270",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "As we can see from fig 1 that the fishing category had most number of sales followed by the Cleats.\n",
    "However it is suprising to see that top 7 products with highest price on average are the most sold products on average with computers having almost 1350 sales despite price being 1500$. \n",
    "\n",
    "Which month or week day recorded highest sales? It can be found by dividing order time into years, months, week day and hour to better observe the trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 95.819025,
     "end_time": "2021-01-13T16:29:00.862048",
     "exception": false,
     "start_time": "2021-01-13T16:27:25.043023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Create a new column for each part of the date (year, month, etc.).\n",
    "## This cell can take a while to run\n",
    "\n",
    "data['order_year']= pd.DatetimeIndex(data['order date (DateOrders)']).year\n",
    "data['order_month'] = pd.DatetimeIndex(data['order date (DateOrders)']).month\n",
    "data['order_week_day'] = pd.DatetimeIndex(data['order date (DateOrders)']).weekday\n",
    "data['order_hour'] = pd.DatetimeIndex(data['order date (DateOrders)']).hour\n",
    "data['order_month_year'] = pd.to_datetime(data['order date (DateOrders)']).dt.to_period('M')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.137127,
     "end_time": "2021-01-13T16:29:01.683688",
     "exception": false,
     "start_time": "2021-01-13T16:29:01.546561",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "So what is the purchase trend in week days, hours and months?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.895542,
     "end_time": "2021-01-13T16:29:02.720699",
     "exception": false,
     "start_time": "2021-01-13T16:29:01.825157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "           \n",
    "## Plot the average sales per year\n",
    "\n",
    "\n",
    "\n",
    "## Plot the average sales per week in days\n",
    "\n",
    "\n",
    "\n",
    "## Plot the average sales per day in hours\n",
    "\n",
    "\n",
    "\n",
    "## Plot the average sales per year in month\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.136323,
     "end_time": "2021-01-13T16:29:02.996875",
     "exception": false,
     "start_time": "2021-01-13T16:29:02.860552",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "How price is impacting sales, when and which products are having more sales are found.\n",
    "The most number of orders came in October followed by November, and orders for all other months are consistent.\n",
    "Highest number of orders are placed by customers in 2017. \n",
    "Saturday recorded highest number of average sales and wednesday with the least number of sales. The average sales are consistent throughout the day irrespective of time with std of 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.135319,
     "end_time": "2021-01-13T16:29:03.267245",
     "exception": false,
     "start_time": "2021-01-13T16:29:03.131926",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "It is also important to know what type of payment method is being preferred by people to buy all these products in all regions? It can be found using the [.unique()](https://pandas.pydata.org/docs/reference/api/pandas.unique.html) method to see different payment methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.157726,
     "end_time": "2021-01-13T16:29:03.561019",
     "exception": false,
     "start_time": "2021-01-13T16:29:03.403293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.132226,
     "end_time": "2021-01-13T16:29:03.823477",
     "exception": false,
     "start_time": "2021-01-13T16:29:03.691251",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "It is found that four types of payment methods are used.\n",
    "\n",
    "Which payment method is preferred the most by people in different regions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 1.240124,
     "end_time": "2021-01-13T16:29:05.197615",
     "exception": false,
     "start_time": "2021-01-13T16:29:03.957491",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "count1 = data[(data['Type'] == 'TRANSFER')]['Order Region'].value_counts()\n",
    "count2 = data[(data['Type'] == 'CASH')]['Order Region'].value_counts()\n",
    "count3 = data[(data['Type'] == 'PAYMENT')]['Order Region'].value_counts()\n",
    "count4 = data[(data['Type'] == 'DEBIT')]['Order Region'].value_counts()\n",
    "names = data['Order Region'].value_counts().keys()\n",
    "\n",
    "n_groups = 23\n",
    "fig,ax = plt.subplots(figsize=(20,8))\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.2\n",
    "opacity = 0.6\n",
    "\n",
    "type1 = plt.bar(index,count1, bar_width, alpha=opacity, color='b', label='Transfer')\n",
    "type2 = plt.bar(index+bar_width, count2, bar_width, alpha=opacity, color='r', label='Cash')\n",
    "type3 = plt.bar(index+bar_width+bar_width, count3, bar_width, alpha=opacity, color='g', label='Payment')\n",
    "type4 = plt.bar(index+bar_width+bar_width+bar_width, count4, bar_width, alpha=opacity, color='y', label='Debit')\n",
    "\n",
    "plt.xlabel('Order Regions')\n",
    "plt.ylabel('Number of payments')\n",
    "plt.title('Different Type of payments used in all regions')\n",
    "plt.legend()\n",
    "plt.xticks(index+bar_width,names,rotation=90)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.13284,
     "end_time": "2021-01-13T16:29:05.465276",
     "exception": false,
     "start_time": "2021-01-13T16:29:05.332436",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Debit type is most preferred payment method by people in all regions, Cash payment being the least preferred method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.134988,
     "end_time": "2021-01-13T16:29:06.725701",
     "exception": false,
     "start_time": "2021-01-13T16:29:06.590713",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Finding which payment method is used to conduct frauds can be useful to prevent fraud from happening in future\n",
    "\n",
    "Hint: Use the [value_counts()](https://pandas.pydata.org/docs/reference/api/pandas.Series.value_counts.html) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.208912,
     "end_time": "2021-01-13T16:29:07.070107",
     "exception": false,
     "start_time": "2021-01-13T16:29:06.861195",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Checking type of payment used to conduct fraud (how many fraud per type of payment)\n",
    "# Your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.137406,
     "end_time": "2021-01-13T16:29:07.346820",
     "exception": false,
     "start_time": "2021-01-13T16:29:07.209414",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "It can be clearly seen that there are no frauds conducted with DEBIT, CASH, or PAYMENT methods so all the suspected fraud orders are made using wire transfer probably from abroad. \n",
    "\n",
    "Which region and what product is being suspected to the fraud the most? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.482881,
     "end_time": "2021-01-13T16:29:07.966727",
     "exception": false,
     "start_time": "2021-01-13T16:29:07.483846",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Get suspected fraud orders made by transfer payment\n",
    "high_fraud = ***** # Your code here\n",
    "\n",
    "## Plotting pie chart with respect to order region\n",
    "fraud = high_fraud['Order Region'].value_counts().plot.pie(figsize=(24,12),\n",
    "                                                  startangle=180, explode=(0.1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0), autopct='%.1f', shadow=True,)\n",
    "\n",
    "plt.title(\"Regions with Highest Fraud\", size=15, color='y') # Plotting title\n",
    "plt.ylabel(\" \")\n",
    "fraud.axis('equal') \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.140097,
     "end_time": "2021-01-13T16:29:08.246460",
     "exception": false,
     "start_time": "2021-01-13T16:29:08.106363",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "It can be observed that highest number of suspected fraud orders are from Western Europe which is approximately 17.4% of total orders followed by Central America with 15.5%. \n",
    "\n",
    "Following the same method, which product is being suspected fraud the most (for all regions and for western europe only)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.508228,
     "end_time": "2021-01-13T16:29:08.895666",
     "exception": false,
     "start_time": "2021-01-13T16:29:08.387438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Plotting bar chart for top 10 most suspected fraud department in all regions and in Western Europe\n",
    "# Your code here\n",
    "fraud_all = *****\n",
    "fraud_WE = *****\n",
    "\n",
    "fraud_all.nlargest(10).plot.bar(figsize=(20,8), title=\"Fraud Category\",color='orange')\n",
    "fraud_WE.nlargest(10).plot.bar(figsize=(20,8), title=\"Fraud product in Western Europe\",color='green')\n",
    "\n",
    "plt.legend([\"All regions\", \"Western Europe\"])\n",
    "plt.title(\"Top 10 products with highest fraud detections\", size=15)\n",
    "plt.xlabel(\"Products\", size=13)\n",
    "plt.ylim(0,600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.141611,
     "end_time": "2021-01-13T16:29:09.177877",
     "exception": false,
     "start_time": "2021-01-13T16:29:09.036266",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "It is very suprising to see that Men's footwear department is being suspected to fraud the most followed by cleats in all the regions and also in Western Europe.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.144696,
     "end_time": "2021-01-13T16:29:10.914719",
     "exception": false,
     "start_time": "2021-01-13T16:29:10.770023",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Delivering products to customer on time without late delivery is another important aspect for a supply chain company. \n",
    "\n",
    "What category of products are being delivered late the most?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.451968,
     "end_time": "2021-01-13T16:29:11.510505",
     "exception": false,
     "start_time": "2021-01-13T16:29:11.058537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "## Filtering columns with late delivery status\n",
    "\n",
    "\n",
    "## Plot bar: Top 10 products with most late deliveries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.146677,
     "end_time": "2021-01-13T16:29:11.840338",
     "exception": false,
     "start_time": "2021-01-13T16:29:11.693661",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "It can be seen that orders with Cleats department is getting delayed the most followed by Men's Footwear.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.162329,
     "end_time": "2021-01-13T16:29:49.511360",
     "exception": false,
     "start_time": "2021-01-13T16:29:49.349031",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Data Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.162977,
     "end_time": "2021-01-13T16:29:49.836550",
     "exception": false,
     "start_time": "2021-01-13T16:29:49.673573",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now that we know the data better, we can start to train models!\n",
    "\n",
    "First, we will prepare the data: separate output variables from features and split train and test sets.\n",
    "\n",
    "Then, classification models will be trained to detect fraud and late delivery and regression models will preict sales and order quantity.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A new dataset is created with the copy of original data for training the data and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.241244,
     "end_time": "2021-01-13T16:29:50.239907",
     "exception": false,
     "start_time": "2021-01-13T16:29:49.998663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.163856,
     "end_time": "2021-01-13T16:29:50.569207",
     "exception": false,
     "start_time": "2021-01-13T16:29:50.405351",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Two new columns are created for orders with suspected fraud and late delivery making them into binary classification (0 or 1), which in turn helps to measure performance of different models better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.232542,
     "end_time": "2021-01-13T16:29:50.964500",
     "exception": false,
     "start_time": "2021-01-13T16:29:50.731958",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "train_data['fraud'] = *****\n",
    "train_data['late_delivery'] = *****\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.158112,
     "end_time": "2021-01-13T16:29:51.282082",
     "exception": false,
     "start_time": "2021-01-13T16:29:51.123970",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now to measure machine models accurately all the columns with repeated values are dropped like `late_delivery_risk` column because, it is known all the products with late delivery risk are delivered late. And `Order Status` column because, a new column for fraud detection is created, so there is a chance machine learning model might take values directly from these columns to predict output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.25896,
     "end_time": "2021-01-13T16:29:51.710126",
     "exception": false,
     "start_time": "2021-01-13T16:29:51.451166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Dropping columns with repeated values\n",
    "train_data.drop(['Delivery Status','Late_delivery_risk','Order Status','order_month_year','order date (DateOrders)'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.158117,
     "end_time": "2021-01-13T16:29:52.030336",
     "exception": false,
     "start_time": "2021-01-13T16:29:51.872219",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "It is important to check the type of variables in the data because machine learning models can only be trained with numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.177026,
     "end_time": "2021-01-13T16:29:52.370722",
     "exception": false,
     "start_time": "2021-01-13T16:29:52.193696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Display the 5 first data\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.16158,
     "end_time": "2021-01-13T16:29:52.695790",
     "exception": false,
     "start_time": "2021-01-13T16:29:52.534210",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "There are some columns with object type data which cannot be trained in machine learning models so all the object type data is converted to int type using preprocessing label encoder library.\n",
    "\n",
    "Hint: use the [LabelEncoder()](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) method from Scikit-Learn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 1.44528,
     "end_time": "2021-01-13T16:29:54.303274",
     "exception": false,
     "start_time": "2021-01-13T16:29:52.857994",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Create the Labelencoder object used to transform categorical values into numeric\n",
    "# Your code here\n",
    "\n",
    "*****\n",
    "\n",
    "## Convert the categorical columns into numeric\n",
    "train_data['Customer Country']  = *****\n",
    "train_data['Market']            = *****\n",
    "train_data['Type']              = *****\n",
    "train_data['Product Name']      = *****\n",
    "train_data['Customer Segment']  = *****\n",
    "train_data['Customer State']    = *****\n",
    "train_data['Order Region']      = *****\n",
    "train_data['Order City']        = *****\n",
    "train_data['Category Name']     = *****\n",
    "train_data['Customer City']     = *****\n",
    "train_data['Department Name']   = *****\n",
    "train_data['Order State']       = *****\n",
    "train_data['Shipping Mode']     = *****\n",
    "train_data['order_week_day']    = *****\n",
    "train_data['Order Country']     = *****\n",
    "train_data['Customer Full Name']= *****\n",
    "\n",
    "## Display the 5 first data\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.170301,
     "end_time": "2021-01-13T16:29:54.639704",
     "exception": false,
     "start_time": "2021-01-13T16:29:54.469403",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now all the data is transformed into int type. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Splitting train and test datasets\n",
    "\n",
    "The dataset is split into train data and test data so models can be trained with train data and the performance of model can be evaluated using test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.509491,
     "end_time": "2021-01-13T16:29:55.673114",
     "exception": false,
     "start_time": "2021-01-13T16:29:55.163623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Your code here\n",
    "\n",
    "## All columns expect fraud\n",
    "\n",
    "\n",
    "## Only fraud column\n",
    "\n",
    "\n",
    "##  Splitting the data into two parts in which 80% data will be used for training the model and 20% for testing\n",
    "\n",
    "\n",
    "# All columns expect late_delivery\n",
    "\n",
    "\n",
    "# Only late delivery column\n",
    "\n",
    "\n",
    "## Splitting the data into two parts in which 80% data will be used for training the model and 20% for testing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.215344,
     "end_time": "2021-01-13T16:29:56.071866",
     "exception": false,
     "start_time": "2021-01-13T16:29:55.856522",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Since there are so many different variables with different ranges [standard scaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) is used to standardize total the data so it is internally consistent before training the data with machine learning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.619554,
     "end_time": "2021-01-13T16:29:56.861914",
     "exception": false,
     "start_time": "2021-01-13T16:29:56.242360",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "xf_train = sc.fit_transform(xf_train)\n",
    "xf_test = sc.transform(xf_test)\n",
    "xl_train = sc.fit_transform(xl_train)\n",
    "xl_test = sc.transform(xl_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.172981,
     "end_time": "2021-01-13T16:29:54.996366",
     "exception": false,
     "start_time": "2021-01-13T16:29:54.823385",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 3.3. Comparision of Classification Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.167707,
     "end_time": "2021-01-13T16:29:57.194568",
     "exception": false,
     "start_time": "2021-01-13T16:29:57.026861",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The data is now ready to be used in machine learning models, since many different models are compared training every model from begining will be redundant so a function is defined to make the process bit easy. \n",
    "The output is in binary classification format so all the models are measured with Accuracy and F1 score metrics. \n",
    "\n",
    "To measure the performance of different models F1 score is used as the main metric because it is the harmonic mean of precison score and recall score.\n",
    "The function will also display the confusion matrix.\n",
    "\n",
    "The parameters of the function will be the name of the task (example : 'fraud detection'), the classifier, the input data train, the input data test, the labels train and the labels test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.180592,
     "end_time": "2021-01-13T16:29:57.541274",
     "exception": false,
     "start_time": "2021-01-13T16:29:57.360682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Your code here\n",
    "## Define a function which train a model and print the accuracy, f1-score, and confuction matrix for prediction\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.159165,
     "end_time": "2021-01-13T16:29:57.860082",
     "exception": false,
     "start_time": "2021-01-13T16:29:57.700917",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 3.3.1 Logistic classification model\n",
    "\n",
    "Train and evaluate a logistic classification model for both fraud detection and late delivery prediction.\n",
    "\n",
    "Hint: Use the [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) algorithm from Scikit-Learn with default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 3.86083,
     "end_time": "2021-01-13T16:30:01.881759",
     "exception": false,
     "start_time": "2021-01-13T16:29:58.020929",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.162781,
     "end_time": "2021-01-13T16:30:02.207352",
     "exception": false,
     "start_time": "2021-01-13T16:30:02.044571",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 3.3.2 Gaussian naive bayes model\n",
    "\n",
    "Train and evaluate a Gaussian naive bayes model for both fraud detection and late delivery prediction.\n",
    "\n",
    "Hint: Use the [GaussianNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html) algorithm from Scikit-Learn with default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.638923,
     "end_time": "2021-01-13T16:30:03.006123",
     "exception": false,
     "start_time": "2021-01-13T16:30:02.367200",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.160034,
     "end_time": "2021-01-13T16:30:03.326746",
     "exception": false,
     "start_time": "2021-01-13T16:30:03.166712",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 3.3.3 Support vector machines\n",
    "\n",
    "Train and evaluate a Support vector machines model for both fraud detection and late delivery prediction.\n",
    "\n",
    "Hint: Use the [LinearSVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html) algorithm from Scikit-Learn with default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 69.459622,
     "end_time": "2021-01-13T16:31:12.949008",
     "exception": false,
     "start_time": "2021-01-13T16:30:03.489386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.161983,
     "end_time": "2021-01-13T16:31:13.271145",
     "exception": false,
     "start_time": "2021-01-13T16:31:13.109162",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 3.3.4 K Nearest Neighbors Classification\n",
    "\n",
    "Train and evaluate a K Nearest Neighbors Classification model for both fraud detection and late delivery prediction.\n",
    "\n",
    "Hint: Use the [KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) algorithm from Scikit-Learn with default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 828.525011,
     "end_time": "2021-01-13T16:45:01.968645",
     "exception": false,
     "start_time": "2021-01-13T16:31:13.443634",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# This cell can take a while to run\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.196289,
     "end_time": "2021-01-13T16:45:05.215522",
     "exception": false,
     "start_time": "2021-01-13T16:45:05.019233",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 3.3.5 Random Forest Classification\n",
    "\n",
    "Train and evaluate a Random Forest model for both fraud detection and late delivery prediction.\n",
    "\n",
    "Hint: Use the [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) algorithm from Scikit-Learn with default parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 57.550459,
     "end_time": "2021-01-13T16:46:02.929529",
     "exception": false,
     "start_time": "2021-01-13T16:45:05.379070",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.163257,
     "end_time": "2021-01-13T16:47:19.496667",
     "exception": false,
     "start_time": "2021-01-13T16:47:19.333410",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 3.3.6 Decision Tree Classification\n",
    "\n",
    "Train and evaluate a Decision Tree model for both fraud detection and late delivery prediction.\n",
    "\n",
    "Hint: Use the [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) algorithm from Scikit-Learn with default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 3.61612,
     "end_time": "2021-01-13T16:47:23.278150",
     "exception": false,
     "start_time": "2021-01-13T16:47:19.662030",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.168434,
     "end_time": "2021-01-13T16:47:50.839710",
     "exception": false,
     "start_time": "2021-01-13T16:47:50.671276",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 3.4. Feature Importance\n",
    "\n",
    "Which variable was given more importance in the model is found using feature importance method from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.819384,
     "end_time": "2021-01-13T16:47:51.826805",
     "exception": false,
     "start_time": "2021-01-13T16:47:51.007421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "important_col = model_f.feature_importances_.argsort()\n",
    "feat_imp = pd.DataFrame({'Variables': xf.columns[important_col], 'importance': model_f.feature_importances_[important_col]})\n",
    "feat_imp = feat_imp.sort_values(by='importance', ascending=False)\n",
    "ax = sns.catplot(x='Variables', y = 'importance', data=feat_imp, height=5, aspect=2, kind=\"bar\")\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.170042,
     "end_time": "2021-01-13T16:47:52.167521",
     "exception": false,
     "start_time": "2021-01-13T16:47:51.997479",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Even though fraud detection is not at all related to Days for shipping(real) it is very surprising to see it was given an importance of 0.12. All other important parameters like customer full name, shipping mode, type of payment used are given an importance of 0.7 which helps the company to detect fraud accurately when same customer is conducting fraud.\n",
    "\n",
    "Same way which variables were given importance for prediction of late delivery is found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 1.100897,
     "end_time": "2021-01-13T16:47:53.439371",
     "exception": false,
     "start_time": "2021-01-13T16:47:52.338474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.223418,
     "end_time": "2021-01-13T16:47:53.860759",
     "exception": false,
     "start_time": "2021-01-13T16:47:53.637341",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "It can be seen that the columns for the days of shipping is given almost 90% importance in decision tree model, it will be interesting to see how well the model can predict when these variables are removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.177337,
     "end_time": "2021-01-13T16:47:54.229630",
     "exception": false,
     "start_time": "2021-01-13T16:47:54.052293",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "So a new model with the copy of train data is created, and we start again the whole process after we drop the two columns `Days for shipping (real)`, `Days for shipment (scheduled)`:\n",
    "1. Copy the dataset\n",
    "2. Drop the columns\n",
    "3. Separate input and labels data\n",
    "4. Split data train and test\n",
    "5. Standardize the data\n",
    "6. Fit the decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "\n",
    "## Dropping columns in new data set\n",
    "\n",
    "\n",
    "## Seperate input and labels data\n",
    "\n",
    "\n",
    "## Splitting the data into two parts in which 80% data will be used for training the model and 20% for testing\n",
    "\n",
    "\n",
    "## Standardize the data\n",
    "\n",
    "\n",
    "## Train the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.176308,
     "end_time": "2021-01-13T16:48:06.255882",
     "exception": false,
     "start_time": "2021-01-13T16:48:06.079574",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Even when shipping days variables were removed the F1 score and the accuracy of the new model is nearly 84% which is still pretty good. Which variables are given more importance this time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.8263,
     "end_time": "2021-01-13T16:48:07.258261",
     "exception": false,
     "start_time": "2021-01-13T16:48:06.431961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.177115,
     "end_time": "2021-01-13T16:48:07.619112",
     "exception": false,
     "start_time": "2021-01-13T16:48:07.441997",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This time variables like shipping mode, order city,state are given more importance which helps company to use different shipping methods to deliver products faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.17867,
     "end_time": "2021-01-13T16:48:16.853765",
     "exception": false,
     "start_time": "2021-01-13T16:48:16.675095",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 3.5. Deep Neural Network Model for Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.176116,
     "end_time": "2021-01-13T16:48:16.488158",
     "exception": false,
     "start_time": "2021-01-13T16:48:16.312042",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Decision Tree classifier is identified as the best model in all Machine learning models for Classification Type data. \n",
    "How well it can perform when compared with Deep Neural Network model?\n",
    "\n",
    "We will use the `Tensorflow-Keras` library and more specifically the [Sequential](https://www.tensorflow.org/guide/keras/sequential_model) model with 9 hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.430522,
     "end_time": "2021-01-13T16:48:17.461858",
     "exception": false,
     "start_time": "2021-01-13T16:48:17.031336",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "keras.layers.BatchNormalization()\n",
    "classifier = Sequential()\n",
    "#First Hidden Layer\n",
    "classifier.add(Dense(1024, activation='relu',kernel_initializer='random_normal', input_dim=43)) #Since we have 43 columns\n",
    "#Third Hidden Layer\n",
    "classifier.add(Dense(512, activation='relu',kernel_initializer='random_normal'))\n",
    "#Fourth Hidden Layer\n",
    "classifier.add(Dense(256, activation='relu',kernel_initializer='random_normal'))\n",
    "#Fifth Hidden Layer\n",
    "classifier.add(Dense(128, activation='relu',kernel_initializer='random_normal'))\n",
    "#Sixth Hidden Layer\n",
    "classifier.add(Dense(64, activation='relu',kernel_initializer='random_normal'))\n",
    "#Seventh Hidden Layer\n",
    "classifier.add(Dense(32, activation='relu',kernel_initializer='random_normal'))\n",
    "#Eight Hidden Layer\n",
    "classifier.add(Dense(16, activation='relu',kernel_initializer='random_normal'))\n",
    "#Ninth Hidden Layer\n",
    "classifier.add(Dense(8, activation='relu',kernel_initializer='random_normal'))\n",
    "#Tenth Hidden Layer\n",
    "classifier.add(Dense(4, activation='relu',kernel_initializer='random_normal'))\n",
    "#Eleventh Hidden Layer\n",
    "classifier.add(Dense(2, activation='relu',kernel_initializer='random_normal'))\n",
    "#Output Layer\n",
    "classifier.add(Dense(1, activation='sigmoid',kernel_initializer='random_normal'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.175906,
     "end_time": "2021-01-13T16:48:17.818440",
     "exception": false,
     "start_time": "2021-01-13T16:48:17.642534",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Since output data is binary classification the `binary_crossentropy` is used to measure loss and `accuracy` is used as metric to train the model because F1 score is not available in Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.199792,
     "end_time": "2021-01-13T16:48:18.194478",
     "exception": false,
     "start_time": "2021-01-13T16:48:17.994686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.177167,
     "end_time": "2021-01-13T16:48:18.548395",
     "exception": false,
     "start_time": "2021-01-13T16:48:18.371228",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The model is trained with batch size of 512 and 40 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 80.116705,
     "end_time": "2021-01-13T16:49:38.841018",
     "exception": false,
     "start_time": "2021-01-13T16:48:18.724313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Fitting the data to the training dataset\n",
    "classifier.fit(xf_train, yf_train, batch_size=512, epochs=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.644197,
     "end_time": "2021-01-13T16:49:40.139707",
     "exception": false,
     "start_time": "2021-01-13T16:49:39.495510",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "It can be seen that the neural network model is performing better at every 20 first epochs even tough accuracy remained same the loss is decreasing. Then, loss is stable which means that we can stop learning.\n",
    "We could continue the training until the loss value stabilises.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 2.106699,
     "end_time": "2021-01-13T16:53:39.429641",
     "exception": false,
     "start_time": "2021-01-13T16:53:37.322942",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The model is evaluated with test data set. See the [Tensorflow-Keras doc](https://www.tensorflow.org/guide/keras/train_and_evaluate) for more infos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 16.304829,
     "end_time": "2021-01-13T16:53:57.782242",
     "exception": false,
     "start_time": "2021-01-13T16:53:41.477413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_evaluate = classifier.evaluate(xf_train, yf_train)\n",
    "test_evaluate = classifier.evaluate(xf_test, yf_test)\n",
    "\n",
    "print('accuracy for Train set is',train_evaluate)\n",
    "print('accuracy for Test set is',test_evaluate) \n",
    "\n",
    "yf_pred1 = classifier.predict(xf_test, batch_size=512, verbose=1)\n",
    "yf_pred = np.argmax(yf_pred1, axis=1)\n",
    "print(f1_score(yf_test, yf_pred, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 2.19449,
     "end_time": "2021-01-13T16:54:02.145020",
     "exception": false,
     "start_time": "2021-01-13T16:53:59.950530",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The f1 score for deep neural network model is 96.48% which is pretty high and better when compared with decision tree f1 score which was 80.64.\n",
    "\n",
    "But comparing accuracy scores it can concluded that even machine learning models did pretty good for fraud detection and late delivery prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 2.133244,
     "end_time": "2021-01-13T16:54:06.411198",
     "exception": false,
     "start_time": "2021-01-13T16:54:04.277954",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 3.6. Comparision of Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 2.253357,
     "end_time": "2021-01-13T16:54:10.930827",
     "exception": false,
     "start_time": "2021-01-13T16:54:08.677470",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "For comparison of regression models `Sales` and `Order Item Quantity` are predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 2.573944,
     "end_time": "2021-01-13T16:54:15.894620",
     "exception": false,
     "start_time": "2021-01-13T16:54:13.320676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "## For Sales\n",
    "## Prepare features and labels data\n",
    "\n",
    "\n",
    "## Split train/test datasets\n",
    "\n",
    "\n",
    "## For Order Item Quantity\n",
    "## Prepare features and labels data\n",
    "\n",
    "\n",
    "## Split train/test datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 2.43543,
     "end_time": "2021-01-13T16:54:20.663448",
     "exception": false,
     "start_time": "2021-01-13T16:54:18.228018",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "MinMax scaler is used to standardize data since data type is regression.\n",
    "\n",
    "Hint: use the [MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html) method from `Scikit-Learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 2.532945,
     "end_time": "2021-01-13T16:54:25.491778",
     "exception": false,
     "start_time": "2021-01-13T16:54:22.958833",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "\n",
    "## Fit and transform input train data (for both sales and quantity sets)\n",
    "\n",
    "\n",
    "\n",
    "## transform input test data (for both sales and quantity sets)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 2.250331,
     "end_time": "2021-01-13T16:54:30.282486",
     "exception": false,
     "start_time": "2021-01-13T16:54:28.032155",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The data is now ready to be used in machine learning models. Since, different models are compared here like above a function is defined. The output is regression type so accuracy cannot be used as a measure to compare different models like classification models, so all the models are compared using mean absolute error (MAE) and RMSE.\n",
    "\n",
    "The lower the value of mean absolute error the better the model is performing and lower values of RMSE indicate better fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 2.262524,
     "end_time": "2021-01-13T16:54:34.912376",
     "exception": false,
     "start_time": "2021-01-13T16:54:32.649852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 2.140097,
     "end_time": "2021-01-13T16:54:39.330628",
     "exception": false,
     "start_time": "2021-01-13T16:54:37.190531",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 3.6.1 Lasso Regression\n",
    "\n",
    "Train and evaluate a Lasso Regression model for both sales and quantity prediction.\n",
    "\n",
    "Hint: Use the [Lasso](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html) algorithm from Scikit-Learn with default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 2.882896,
     "end_time": "2021-01-13T16:54:44.419254",
     "exception": false,
     "start_time": "2021-01-13T16:54:41.536358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 2.16531,
     "end_time": "2021-01-13T16:54:48.702996",
     "exception": false,
     "start_time": "2021-01-13T16:54:46.537686",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 3.6.2 Ridge Regression\n",
    "\n",
    "Train and evaluate a Ridge Regression model for both sales and quantity prediction.\n",
    "\n",
    "Hint: Use the [Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html) algorithm from Scikit-Learn with default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 2.296801,
     "end_time": "2021-01-13T16:54:53.106369",
     "exception": false,
     "start_time": "2021-01-13T16:54:50.809568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 2.166736,
     "end_time": "2021-01-13T16:54:57.566298",
     "exception": false,
     "start_time": "2021-01-13T16:54:55.399562",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 3.6.3 Gradient Boosting Regression\n",
    "\n",
    "Train and evaluate a Gradient Boosting Regression model for both sales and quantity prediction.\n",
    "\n",
    "Hint: Use the [GradientBoostingRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html) algorithm from Scikit-Learn with default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 6.311747,
     "end_time": "2021-01-13T16:55:06.127531",
     "exception": false,
     "start_time": "2021-01-13T16:54:59.815784",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 2.109486,
     "end_time": "2021-01-13T16:55:10.441738",
     "exception": false,
     "start_time": "2021-01-13T16:55:08.332252",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 3.6.4 Random Forest Regression\n",
    "\n",
    "Train and evaluate a Random Forest Regression model for both sales and quantity prediction.\n",
    "\n",
    "Hint: Use the [RandomForestRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) algorithm from Scikit-Learn with default parameters. Use max_depth=10 to limit the size of the trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 262.220947,
     "end_time": "2021-01-13T16:59:34.780219",
     "exception": false,
     "start_time": "2021-01-13T16:55:12.559272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 2.238255,
     "end_time": "2021-01-13T17:00:24.837297",
     "exception": false,
     "start_time": "2021-01-13T17:00:22.599042",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 3.6.5 Decision Tree Regression\n",
    "\n",
    "Train and evaluate a Decision Tree Regression model for both sales and quantity prediction.\n",
    "\n",
    "Hint: Use the [DecisionTreeRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html) algorithm from Scikit-Learn with default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 7.52772,
     "end_time": "2021-01-13T17:00:34.540563",
     "exception": false,
     "start_time": "2021-01-13T17:00:27.012843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 2.140909,
     "end_time": "2021-01-13T17:00:38.835279",
     "exception": false,
     "start_time": "2021-01-13T17:00:36.694370",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 3.6.6 Linear Regression\n",
    "\n",
    "Train and evaluate a Decision Tree Regression model for both sales and quantity prediction.\n",
    "\n",
    "Hint: Use the [LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) algorithm from Scikit-Learn with default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 2.404801,
     "end_time": "2021-01-13T17:00:43.414611",
     "exception": false,
     "start_time": "2021-01-13T17:00:41.009810",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 2.126582,
     "end_time": "2021-01-13T17:01:13.872782",
     "exception": false,
     "start_time": "2021-01-13T17:01:11.746200",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here suprisingly, Linear regression model performed better in comparision to other models followed by decision tree regression model for predicting sales.\n",
    "For predicting order quantity Random forest did very good. How well these models perform against neural network model perform to predict order quantity?\n",
    "\n",
    "The neural network model is trained with 5 hidden layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 2.159377,
     "end_time": "2021-01-13T17:01:18.159294",
     "exception": false,
     "start_time": "2021-01-13T17:01:15.999917",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 3.7. Neural Network Model for Regression\n",
    "\n",
    "\n",
    "Again, we will use the `Tensorflow-Keras` library and more specifically the [Sequential](https://www.tensorflow.org/guide/keras/sequential_model) model with 4 hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 2.212907,
     "end_time": "2021-01-13T17:01:22.544154",
     "exception": false,
     "start_time": "2021-01-13T17:01:20.331247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "regressor = Sequential()\n",
    "\n",
    "#First Hidden Layer\n",
    "regressor.add(Dense(512, activation='relu', kernel_initializer='normal', input_dim=43))\n",
    "#Second  Hidden Layer\n",
    "regressor.add(Dense(256, activation='relu', kernel_initializer='normal'))\n",
    "#Third  Hidden Layer\n",
    "regressor.add(Dense(256, activation='relu', kernel_initializer='normal'))\n",
    "#Fourth  Hidden Layer\n",
    "regressor.add(Dense(256, activation='relu', kernel_initializer='normal'))\n",
    "#Fifth  Hidden Layer\n",
    "regressor.add(Dense(256, activation='relu', kernel_initializer='normal'))\n",
    "\n",
    "#Output Layer\n",
    "regressor.add(Dense(1, activation='linear'))# Linear activation is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 2.183366,
     "end_time": "2021-01-13T17:01:26.922335",
     "exception": false,
     "start_time": "2021-01-13T17:01:24.738969",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The mean absolute error is used as loss metric to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 2.147446,
     "end_time": "2021-01-13T17:01:31.232417",
     "exception": false,
     "start_time": "2021-01-13T17:01:29.084971",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "regressor.compile(optimizer='adam', loss='mean_absolute_error', metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 245.43129,
     "end_time": "2021-01-13T17:06:38.790686",
     "exception": false,
     "start_time": "2021-01-13T17:02:33.359396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "regressor.fit(xq_train, yq_train, batch_size=256, epochs=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 4.325855,
     "end_time": "2021-01-13T17:07:51.918145",
     "exception": false,
     "start_time": "2021-01-13T17:07:47.592290",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The test data is evaluated to find the MAE, RMSE values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 18.406436,
     "end_time": "2021-01-13T17:08:14.635939",
     "exception": false,
     "start_time": "2021-01-13T17:07:56.229503",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_train_q = regressor.predict(xq_train)\n",
    "pred_q_test = regressor.predict(xq_test)\n",
    "print('MAE Value train data:',regressor.evaluate(xq_train,yq_train))\n",
    "print('RMSE of train data:',np.sqrt(mean_squared_error(yq_train,pred_train_q)))\n",
    "print('MAE Value test data:',regressor.evaluate(xq_test,yq_test))\n",
    "print('RMSE of test data:',np.sqrt(mean_squared_error(yq_test,pred_q_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 4.286906,
     "end_time": "2021-01-13T17:08:23.245465",
     "exception": false,
     "start_time": "2021-01-13T17:08:18.958559",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The MAE and RMSE scores for neural network models are 0.022 and 0.065 which are pretty good. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 4.385291,
     "end_time": "2021-01-13T17:08:57.776504",
     "exception": false,
     "start_time": "2021-01-13T17:08:53.391213",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('dsc-5gi-py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "papermill": {
   "duration": 2531.178491,
   "end_time": "2021-01-13T17:09:02.331724",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-01-13T16:26:51.153233",
   "version": "2.1.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "e2fb648020b1069e7a43683ce727dd7a5cc2adae8ff6628eafc57da972ef564f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
